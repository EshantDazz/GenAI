{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('myenv/.env')\n",
    "a=os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key=a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"/Users/eshantdas/Desktop/Deeplearning_hehehe/Advance_lag/ebook.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge all of this into a single large document\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Automerge Retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "# create the hierarchical node parser w/ default settings\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 512, 128]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Node ID: 60483177-fe18-466c-b57d-74fb670bc1f8\n",
      "Text: Chapter 11: Overcoming Imposter Syndrome. Final Thoughts: Make\n",
      "Every Day Count.LEARNING PROJECTS JOB  PAGE 4Coding AI Is the New\n",
      "Literacy Today we take it for granted that many people know how to\n",
      "read and write. Someday, I hope,  it will be just as common that\n",
      "people know how to write code, specifically for AI. Several hundred\n",
      "years ago, society...\n",
      "<class 'llama_index.core.schema.TextNode'>\n",
      "------\n",
      "------\n",
      "------\n",
      "------\n",
      "Chapter 11: Overcoming Imposter Syndrome.\n",
      "Final Thoughts: Make Every Day Count.LEARNING\n",
      "PROJECTS\n",
      "JOB\n",
      "\n",
      "PAGE 4Coding AI Is the New Literacy\n",
      "Today we take it for granted that many people know how to read and write. Someday, I hope, \n",
      "it will be just as common that people know how to write code, specifically for AI.\n",
      "Several hundred years ago, society didn’t view language literacy as a necessary skill. A small \n",
      "number of people learned to read and write, and everyone else let them do the reading and \n",
      "writing.\n"
     ]
    }
   ],
   "source": [
    "#get the leaf nodes\n",
    "\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "print(type(leaf_nodes))\n",
    "print(leaf_nodes[2])\n",
    "print(type(leaf_nodes[2]))\n",
    "print('------')\n",
    "print('------')\n",
    "print('------')\n",
    "print('------')\n",
    "print(leaf_nodes[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: bdf7a490-eb11-4fc9-ae3f-09a1b6d1917a\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide   PAGE 2\"AI is the new\n",
      "electricity. It will  transform and improve  all areas of human life.\"\n",
      "Andrew Ng  PAGE 3Table of  ContentsIntroduction: Coding AI is the New\n",
      "Literacy. Chapter 1: Three Steps to Career Growth. Chapter 2: Learning\n",
      "T...\n",
      "PAGE 1Founder, DeepLearning.AICollected Insights\n",
      "from Andrew Ng\n",
      "How to \n",
      "Build\n",
      "Your\n",
      "Career\n",
      "in AIA Simple Guide\n",
      "\n",
      "\n",
      "PAGE 2\"AI is the new \n",
      "electricity. It will \n",
      "transform and improve \n",
      "all areas of human life.\"\n",
      "Andrew Ng\n",
      "\n",
      "PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Career Growth.\n",
      "Chapter 2: Learning Technical Skills for a \n",
      "Promising AI Career.\n",
      "Chapter 3: Should You Learn Math to Get a Job \n",
      "in AI?\n",
      "Chapter 4: Scoping Successful AI Projects.\n",
      "Chapter 5: Finding Projects that Complement \n",
      "Your Career Goals.\n",
      "Chapter 6: Building a Portfolio of Projects that \n",
      "Shows Skill Progression.\n",
      "Chapter 7: A Simple Framework for Starting Your AI \n",
      "Job Search.\n",
      "Chapter 8: Using Informational Interviews to Find \n",
      "the Right Job.\n",
      "Chapter 9: Finding the Right AI Job for You.\n",
      "Chapter 10: Keys to Building a Career in AI.\n",
      "Chapter 11: Overcoming Imposter Syndrome.\n",
      "Final Thoughts: Make Every Day Count.LEARNING\n",
      "PROJECTS\n",
      "JOB\n",
      "\n",
      "PAGE 4Coding AI Is the New Literacy\n",
      "Today we take it for granted that many people know how to read and write. Someday, I hope, \n",
      "it will be just as common that people know how to write code, specifically for AI.\n",
      "Several hundred years ago, society didn’t view language literacy as a necessary skill. A small \n",
      "number of people learned to read and write, and everyone else let them do the reading and \n",
      "writing. It took centuries for literacy to spread, and now society is far richer for it.\n",
      "Words enable deep human-to-human communication. Code is the deepest form of human-to-\n",
      "machine communication. As machines become more central to daily life, that communication \n",
      "becomes ever more important.\n",
      "Traditional software engineering — writing programs that explicitly tell a computer sequences \n",
      "of steps to execute — has been the main path to code literacy. Many introductory programming \n",
      "classes use creating a video game or building a website as examples. But AI, machine learning, \n",
      "and data science offer a new paradigm in which computers extract knowledge from data. This \n",
      "technology offers an even better pathway to coding.\n",
      "Many Sundays, I buy a slice of pizza from my neighborhood pizza parlor.\n"
     ]
    }
   ],
   "source": [
    "nodes_by_id = {node.node_id: node for node in nodes}\n",
    "\n",
    "parent_node = nodes_by_id[leaf_nodes[2].parent_node.node_id]\n",
    "print(parent_node)\n",
    "print(parent_node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BUILDING THE INDEX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "embed_model=OpenAIEmbedding(api_key=a)\n",
    "\n",
    "# embed_model = AzureOpenAIEmbedding(\n",
    "#     model=\"text-embedding-ada-002\",\n",
    "#     deployment_name=\"ada-embedding-model\",\n",
    "#     api_key='af2c3176c0d04bbc9f3db40e570869e1',\n",
    "#     azure_endpoint='https://iprodata.openai.azure.com',\n",
    "#     api_version='2023-05-15'\n",
    "# )\n",
    "# llm = AzureOpenAI(\n",
    "#     model=\"gpt-4-32k\",\n",
    "#     deployment_name=\"gpt432\",\n",
    "#     api_key='72b9712ff8ec450a9d6000898d9cba94',\n",
    "#     azure_endpoint='https://uksouth-gpt432.openai.azure.com',\n",
    "#     api_version='2023-05-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/gkhqvlr92js55bf3s7q8jr000000gp/T/ipykernel_47158/2158502765.py:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  auto_merging_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "\n",
    "auto_merging_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "#Here we construct our index\n",
    "#only the leaf nodes are indexed and all the other nodes are stored in a doc store and are retrieved dynamically during retrieval\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "automerging_index = VectorStoreIndex(\n",
    "    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\n",
    ")\n",
    "\n",
    "automerging_index.storage_context.persist(persist_dir=\"./merging_index/random_string2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Optional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is optional to check\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "if not os.path.exists(\"./merging_index\"):\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes,\n",
    "            storage_context=storage_context,\n",
    "            service_context=auto_merging_context\n",
    "        )\n",
    "\n",
    "    automerging_index.storage_context.persist(persist_dir=\"./merging_index/random_string/\")\n",
    "else:\n",
    "    automerging_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./merging_index/random_string/\"),\n",
    "        service_context=auto_merging_context\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `---------------------------------------------------------------------------------------------------`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "automerging_retriever = automerging_index.as_retriever(\n",
    "    similarity_top_k=12\n",
    ")\n",
    "\n",
    "retriever = AutoMergingRetriever(\n",
    "    automerging_retriever, \n",
    "    automerging_index.storage_context, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "rerank = SentenceTransformerRerank(top_n=6, model=\"BAAI/bge-reranker-base\")\n",
    "\n",
    "auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "    automerging_retriever, node_postprocessors=[rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merging_response = auto_merging_engine.query(\n",
    "    \"What is the importance of networking in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Networking in AI is crucial as it helps individuals build a strong professional community that can provide valuable information, support, and opportunities. By connecting with others in the field, individuals can receive guidance, advice, and potential referrals to employers. Additionally, networking allows individuals to showcase their expertise, receive encouragement for further development, and feel a sense of belonging within the AI community. This support system can be instrumental in advancing one's career and navigating the challenges and opportunities within the AI industry."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(auto_merging_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core import (\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model,\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    merging_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=merging_context,\n",
    "        )\n",
    "    return automerging_index\n",
    "\n",
    "\n",
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=6,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/gkhqvlr92js55bf3s7q8jr000000gp/T/ipykernel_47158/983829541.py:28: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  merging_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "index = build_automerging_index(\n",
    "    [document],\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    save_dir=\"./merging_index/random_string2/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_automerging_query_engine(index, similarity_top_k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merging_response = query_engine.query(\n",
    "    \"What is the importance of networking in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Networking in AI is crucial as it allows individuals to build a strong professional network that can provide valuable information, support, and opportunities. By connecting with others in the field, individuals can receive advice, referrals to potential employers, and stay updated on the latest trends and technologies in AI. Additionally, networking can help individuals establish themselves as experts in the field, leading to recognition and further opportunities for growth and development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(auto_merging_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
